{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3693233-891c-4cf9-97e3-0d1e7f8953a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n",
      "An error occured: failed to find tool template (status code: 500)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If you are working on a task, continue. If not, use getNextTask to get the next task.\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_ollama/chat_models.py:703\u001b[0m, in \u001b[0;36mChatOllama._achat_stream_with_aggregation\u001b[0;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aiterate_over_stream(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_chunk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_ollama/chat_models.py:818\u001b[0m, in \u001b[0;36mChatOllama._aiterate_over_stream\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m is_thinking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acreate_chat_stream(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream_resp, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_ollama/chat_models.py:651\u001b[0m, in \u001b[0;36mChatOllama._acreate_chat_stream\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 651\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_client\u001b[38;5;241m.\u001b[39mchat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mchat_params):\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ollama/_client.py:677\u001b[0m, in \u001b[0;36mAsyncClient._request.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m():\n\u001b[0;32m--> 677\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mstream(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:199\u001b[0m, in \u001b[0;36m_AsyncGeneratorContextManager.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m anext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:1583\u001b[0m, in \u001b[0;36mAsyncClient.stream\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m   1570\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m   1571\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   1572\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1581\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m   1582\u001b[0m )\n\u001b[0;32m-> 1583\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m   1584\u001b[0m     request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[1;32m   1585\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m   1586\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1587\u001b[0m     stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1588\u001b[0m )\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:1629\u001b[0m, in \u001b[0;36mAsyncClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m   1627\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m-> 1629\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m   1630\u001b[0m     request,\n\u001b[1;32m   1631\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m   1632\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1633\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m   1634\u001b[0m )\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:1657\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1657\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m   1658\u001b[0m         request,\n\u001b[1;32m   1659\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1660\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m   1661\u001b[0m     )\n\u001b[1;32m   1662\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:1694\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[0;32m-> 1694\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:1730\u001b[0m, in \u001b[0;36mAsyncClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1730\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transport\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncByteStream)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_transports/default.py:394\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 394\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_async/connection_pool.py:256\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_async/connection_pool.py:236\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mhandle_async_request(\n\u001b[1;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_async/connection.py:103\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_async/http11.py:136\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_async/http11.py:106\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_async/http11.py:177\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_async/http11.py:217\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_backends/anyio.py:35\u001b[0m, in \u001b[0;36mAnyIOStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39mreceive(max_bytes\u001b[38;5;241m=\u001b[39mmax_bytes)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mEndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py:1254\u001b[0m, in \u001b[0;36mSocketStream.receive\u001b[0;34m(self, max_bytes)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mresume_reading()\n\u001b[0;32m-> 1254\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mread_event\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mpause_reading()\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/locks.py:214\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py:5444\u001b[0m, in \u001b[0;36mRunnableBindingBase.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5437\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   5438\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mainvoke\u001b[39m(\n\u001b[1;32m   5439\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[1;32m   5445\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   5446\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   5447\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   5448\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:400\u001b[0m, in \u001b[0;36mBaseChatModel.ainvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 400\u001b[0m llm_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[1;32m    401\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    402\u001b[0m     stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    403\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    404\u001b[0m     tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    405\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    406\u001b[0m     run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    407\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    409\u001b[0m )\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m, llm_result\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:974\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 974\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[1;32m    975\u001b[0m     prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    976\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:894\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m input_messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    892\u001b[0m     _normalize_messages(message_list) \u001b[38;5;28;01mfor\u001b[39;00m message_list \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m    893\u001b[0m ]\n\u001b[0;32m--> 894\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m    896\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate_with_cache(\n\u001b[1;32m    897\u001b[0m             m,\n\u001b[1;32m    898\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    899\u001b[0m             run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    900\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    901\u001b[0m         )\n\u001b[1;32m    902\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages)\n\u001b[1;32m    903\u001b[0m     ],\n\u001b[1;32m    904\u001b[0m     return_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    905\u001b[0m )\n\u001b[1;32m    906\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 211\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(steps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:                     \n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mastream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages}, config, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    212\u001b[0m             step[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpretty_print()\n\u001b[1;32m    213\u001b[0m             \u001b[38;5;66;03m#print(re.sub(\"(<think>[^<]*</think>)\", \"\", output))\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2767\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mamatch_cached_writes():\n\u001b[1;32m   2766\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2767\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39matick(\n\u001b[1;32m   2768\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   2769\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2770\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2771\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maaccept_push,\n\u001b[1;32m   2772\u001b[0m ):\n\u001b[1;32m   2773\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2774\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[1;32m   2775\u001b[0m         stream_mode,\n\u001b[1;32m   2776\u001b[0m         print_mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2779\u001b[0m         asyncio\u001b[38;5;241m.\u001b[39mQueueEmpty,\n\u001b[1;32m   2780\u001b[0m     ):\n\u001b[1;32m   2781\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langgraph/pregel/runner.py:295\u001b[0m, in \u001b[0;36mPregelRunner.atick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    293\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[1;32m    296\u001b[0m         t,\n\u001b[1;32m    297\u001b[0m         retry_policy,\n\u001b[1;32m    298\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream,\n\u001b[1;32m    299\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    300\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[1;32m    301\u001b[0m                 _acall,\n\u001b[1;32m    302\u001b[0m                 weakref\u001b[38;5;241m.\u001b[39mref(t),\n\u001b[1;32m    303\u001b[0m                 stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream,\n\u001b[1;32m    304\u001b[0m                 retry_policy\u001b[38;5;241m=\u001b[39mretry_policy,\n\u001b[1;32m    305\u001b[0m                 futures\u001b[38;5;241m=\u001b[39mweakref\u001b[38;5;241m.\u001b[39mref(futures),\n\u001b[1;32m    306\u001b[0m                 schedule_task\u001b[38;5;241m=\u001b[39mschedule_task,\n\u001b[1;32m    307\u001b[0m                 submit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[1;32m    308\u001b[0m                 loop\u001b[38;5;241m=\u001b[39mloop,\n\u001b[1;32m    309\u001b[0m             ),\n\u001b[1;32m    310\u001b[0m         },\n\u001b[1;32m    311\u001b[0m     )\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langgraph/pregel/retry.py:137\u001b[0m, in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    139\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langgraph/utils/runnable.py:676\u001b[0m, in \u001b[0;36mRunnableSeq.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[1;32m    673\u001b[0m                 step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[1;32m    674\u001b[0m             )\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 676\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langgraph/utils/runnable.py:433\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m             ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langgraph/prebuilt/chat_agent_executor.py:525\u001b[0m, in \u001b[0;36mcreate_react_agent.<locals>.acall_model\u001b[0;34m(state, config)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21macall_model\u001b[39m(state: StateSchema, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StateSchema:\n\u001b[1;32m    524\u001b[0m     state \u001b[38;5;241m=\u001b[39m _get_model_input_state(state)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m cast(AIMessage, \u001b[38;5;28;01mawait\u001b[39;00m model_runnable\u001b[38;5;241m.\u001b[39mainvoke(state, config))\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[1;32m    527\u001b[0m     response\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py:3089\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3087\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3088\u001b[0m                 part \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(step\u001b[38;5;241m.\u001b[39mainvoke, input_, config)\n\u001b[0;32m-> 3089\u001b[0m             input_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro_with_context(part(), context, create_task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3090\u001b[0m     \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!pip install -qU langgraph langchain langchain-community langchainhub langchain-core langchain_ollama ddgs\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import uuid\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "sys.path.insert(0, '/home/bfhgfe/agent')\n",
    "import Tools.search\n",
    "from Tools.search import search\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    AnyMessage,\n",
    "    ToolMessage,\n",
    "    trim_messages,\n",
    ")\n",
    "from langchain_core.messages.utils import count_tokens_approximately\n",
    "\n",
    "llm = ChatOllama(model=\"qwen3:1.7b\")\n",
    "memory = MemorySaver()\n",
    "\n",
    "whoaminow = \"\"\"\n",
    "You are a helpful ai assistant, who analyzes texts.\n",
    "\"\"\"\n",
    "\n",
    "taskrules = \"\"\"\n",
    "Analysis tasks for a text can be gotten from the getNextTask tool.\n",
    "The tool will inform you when there are no further tasks. \n",
    "Do not assume the text itself is a valid source by default.\n",
    "After you finish a task set your status to \"no tasks assigned\".\n",
    "\"\"\"\n",
    "\n",
    "textToAdd = \"\"\"\n",
    "<text>\n",
    "The Big Ole Smelly Elephant In The Substack Room\n",
    "We all know its there, but it’s awkward to talk about it\n",
    "By Kelly Carmichael\n",
    "\n",
    "Jul 14, 2025\n",
    "\n",
    "Back in 1995, through a series of bizarre circumstances, I found myself founding the first ever hair and beauty website on the Internet.\n",
    "\n",
    "I was working as a software engineer at the time when my hairdresser begged me to build him a website. He wanted to sell two homegrown hair videos he’d created.\n",
    "\n",
    "Back in the mid-1990s, WordPress didn’t exist. I had to develop the entire site by myself, writing HTML code. It was agonizing, but a great learning experience.\n",
    "\n",
    "After a few months, the hairdresser, who sold tons of his videos through the site, decided it was too much work and wanted to quit.\n",
    "\n",
    "Excuse me?\n",
    "\n",
    "Considering he never paid me the money he owed me, provided me with any commission, or even thanked me, I was flabbergasted.\n",
    "\n",
    "Eventually, he signed paperwork turning the site back over to me. I promptly changed the name and design, and went on from there. The website was a huge success and is still in business today after 30 years.\n",
    "The hairdresser? He went out of business.\n",
    "\n",
    "Since my nights sweating blood and tears writing feral HTML code, I’ve lurked on new websites and social media channels as they appeared on the landscape.\n",
    "\n",
    "Sometimes, like in the case of BlueSky and Lumo, I was invited in during their Beta versions. Mostly, I just hung out in the shadows.\n",
    "\n",
    "Over many years, checking out new sites and channels, one thing is clear. There are always good and not-so-good parts of any web property.\n",
    "\n",
    "Substack first rolled out its new platform in August 2012. I joined in early 2013. I’d already joined Quora in January of 2012 and was a tad slow to embrace Substack. I lurked there for a while, but it wasn’t until 2017 that I officially joined the platform.\n",
    "\n",
    "Initially, I felt so welcome at Quora that I split my writing time between my own web properties and the Q&A site. I was also very active in the early days of Twitter (X), Instagram, and YouTube.\n",
    "\n",
    "Although I wish I could get by without any sleep, I’ve discovered there are limited hours in a day. I have to thoughtfully schedule my writing time on different platforms.\n",
    "\n",
    "While Substack is free to use for creating and distributing free content, the platform charges a 10% platform fee on all paid subscription revenue. That’s in addition to Stripe’s payment processing fees (2.9% + $0.30 per transaction). The 10% fee applies when writers enable paid subscriptions.\n",
    "\n",
    "If you only have a few subscribers, your platform fees are reasonable. But if you have thousands of subscribers, like some Substackers do, the fees can become substantial.\n",
    "\n",
    "In 2023 and 2024, as many of my friends and writing buddies transitioned from other platforms to Substack, I decided to start writing there after a period of dormancy.\n",
    "\n",
    "There are many things to love about Substack, but there is one elephant in the room that makes it awkward and uncomfortable. I’ve found that as I’ve built a strong community, many of my Substack friends openly ask me to buy a paid membership for their newsletters.\n",
    "\n",
    "Don’t get me wrong, I’m a writer and believe that writers should get paid fairly for their work. But I follow and am connected to over 500 Substackers. I currently have paid subscriptions to ten of my closest writer friends at an average of $8/ 8/month.\n",
    "\n",
    "Do the math. That’s a lot of money to pay. Especially since most don’t reciprocate by buying a subscription to my newsletter.\n",
    "\n",
    "I’m constantly receiving private messages on Substack asking me to buy a subscription to different newsletters. I also receive constant requests to send tips, KoFis, or buy an array of products, from artwork and logos to private consultations.\n",
    "\n",
    "If I bought a subscription to all 500 of the Substackers I follow at an average price of $5–8 per month, I would have to get two more full-time jobs to pay the fees.\n",
    "\n",
    "While I love the Substack platform and the fantastic community, I constantly struggle with the fact that each and every Substack newsletter is a separate entity. Nothing is bundled together.\n",
    "\n",
    "Each newsletter has its own independent subscription fees that are set by the individual writers. If I want to cancel my subscriptions, I have to do each one individually.\n",
    "\n",
    "The subscriptions all produce a constant stream of content. Sometimes my email gets horribly clogged with new content. As much as I try, I can’t keep up.\n",
    "\n",
    "Since I know all ten of the writers I subscribe to, I feel intense guilt if I don’t read, heart, comment, and restack their new work. I also have a panic attack if I consider cancelling any of them.\n",
    "\n",
    "Time management is an ongoing struggle. How do I possibly read constant new content from ten writers? I feel I must stay on top of their work, not just to show support, but also because I’m paying for it. I hate myself when I subscribe to a publication and never read the content.\n",
    "\n",
    "Honestly, sometimes I have subscription fatigue. Before I can snap out of it, someone else will send me a message asking me to subscribe, tip them on KoFi, or do both. I have to decline, and I feel bad. It’s frustrating, maddening, and guilt-producing.\n",
    "\n",
    "While Substack offers a fantastic platform for creators to directly monetize their writing and connect with readers, the individual nature of each newsletter’s subscription model creates challenges for readers like me.\n",
    "\n",
    "I love to support writers, but trying to pick who to subscribe to is stressful. While I can be polite and say no, I hate to ever let anyone down. Especially fellow writers.\n",
    "\n",
    "As much as I love the great features Substack offers and the many fantastic writers, I find myself struggling with a love/hate relationship with the platform.\n",
    "\n",
    "I have paid subscriptions to The Atlantic and Vanity Fair, as well as a few online news publications. I don’t mind paying for those subscriptions, just as I didn’t mind paying for this platform or Quora’s monthly fee.\n",
    "\n",
    "That’s because I have access to the entire publication, not just one writer.\n",
    "\n",
    "I don’t mind the fees Substack charges, but I do mind being constantly asked to buy tips or subscriptions. It makes me uncomfortable, and I feel awkward.\n",
    "\n",
    "Yes, I understand that Substack writers are trying to make a living, but I can’t provide a paid subscription to every writer I follow.\n",
    "\n",
    "And of course, there’s the other elephant in the room. How do you decide which writers to subscribe to versus others? I wish I had a good answer for this ongoing dilemma, but I really don’t.\n",
    "\n",
    "For now, I just do the best I can with the budget I have and hope everyone understands the situation.</text>\n",
    "Now that you have retrieved this text, there is no need to retrieve it again.\n",
    "\"\"\"\n",
    "\n",
    "def getText():\n",
    "    \"\"\"\n",
    "    args: None\n",
    "    returns: a string containing a text.\n",
    "    \"\"\"\n",
    "    return textToAdd\n",
    "\n",
    "\n",
    "steps = [\n",
    "    \"\"\"1. Your first task is to use the getText tool to get the text. Now that you have the text, try and determine the following:\n",
    "        a. the author\n",
    "        b. when the text was written\n",
    "        c. where it was published\n",
    "        d. why the text was written\n",
    "        e. what the text is about\n",
    "        f. if the text is intended as a work of fiction, autobiographical, informative, persuasive, or something else.\"\"\",\n",
    "    \"\"\"2. Summarize any claims the text makes into a list. For each claim, try and determine whether the claim is internally consistent with the rest of the claims made.\n",
    "         For each consistent claim, try and determine whether it is subjective or objective.\"\"\",\n",
    "    \"\"\"3.For each objective consistent claim, use the search tool to determine whether it is likely to be true. Try to find sources other than the original article online supporting or contradicting each claim. Do not assume the provided text is reliable. Favor authoritative sources (well-regarded research institutions, primary evidentiary documents, well-regarded experts)\n",
    "            over internet rumors and hearsay. Make an assessment based on the quality of external sources as to what is likely to be true. Cite external sources used.\n",
    "            \"\"\",\n",
    "]\n",
    "steps = steps[::-1]\n",
    "currentStatus = \"No task assigned.\"\n",
    "def checkStatus():\n",
    "    \"\"\"\n",
    "    Checks the current status if set.\n",
    "    \"\"\"\n",
    "    return currentStatus\n",
    "\n",
    "def setStatus(status:str):\n",
    "    \"\"\"Sets current status to status\n",
    "        args:\n",
    "            status (string)\n",
    "    \"\"\"\n",
    "    currentStatus = status\n",
    "\n",
    "def getNextTask():\n",
    "    \"\"\"Get the next task.\n",
    "    Analysis tasks for a text can be gotten from the getNextTask tool.\n",
    "The tool will inform you when there are no further tasks. \n",
    "    \"\"\"\n",
    "    if len(steps) > 0:\n",
    "        task = steps.pop()\n",
    "        currentStatus = task\n",
    "        if len(steps) > 0:\n",
    "            after=\" There are more tasks remaining after this, so remember to call getNextTask again when you finish this task. Summarize everything you have learned so far and feed it to the consolidate tool. This will replace the message history up to here with your summary. Don't include the text itself.\"\n",
    "            taskstr = f\"\"\"<task>{task}{after}</task>\"\"\"\n",
    "            return str.format(taskstr, task,after)\n",
    "        if len(steps) == 0:\n",
    "            after=\" This is the last task, so you don't need to call getNextTask again. Thank you for the hard work.\"\n",
    "            taskstr = f\"\"\"<task>{task}{after}</task>\"\"\"\n",
    "            return str.format(taskstr, task,after)\n",
    "    else:\n",
    "        return \" All tasks that are currently available have been assigned. Check your status to see if there is an unfinished task in progress. If so, please finish the last task, otherwise, thank you for your hard work today.\"\n",
    "\n",
    "def consolidate(summary:str):\n",
    "    \"\"\"consolidates memories\n",
    "        args: summary(string) takes a summary of what you've learned, replaces the message history with it.\n",
    "        Does not replace status.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    messages.append(AIMessage(content=summary, additional_kwargs={}, response_metadata={}))\n",
    "    messages.append(HumanMessage(content=\"Get the text using getText. Then use getNextTask to get the next task.\", additional_kwargs={}, response_metadata={}))\n",
    "                                \n",
    "    \n",
    "    \n",
    "etiquette = str.format(f\"\"\"\n",
    "User: {whoaminow}\n",
    "System: {taskrules}\n",
    "\"\"\", whoaminow, taskrules)\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[search, getText, getNextTask, checkStatus, setStatus, consolidate],\n",
    "    prompt=etiquette,\n",
    "    checkpointer = memory\n",
    ")\n",
    "\n",
    "messages = []\n",
    "uuidVal = uuid.uuid4()\n",
    "config = {\n",
    "            \"recursion_limit\": 200,\n",
    "            \"configurable\": {\"thread_id\": str(uuidVal)},\n",
    "            \"repetition penalty\": 1.08,\n",
    "            \"DRY\": 1\n",
    "        }\n",
    "\n",
    "messages.append(HumanMessage(content=\"If you are working on a task, continue. If not, use getNextTask to get the next task.\", additional_kwargs={}, response_metadata={}))        \n",
    "\n",
    "while len(steps) > 1:\n",
    "    try:                     \n",
    "        async for step in agent.astream({\"messages\": messages}, config, stream_mode=\"values\"):\n",
    "            step[\"messages\"][-1].pretty_print()\n",
    "            #print(re.sub(\"(<think>[^<]*</think>)\", \"\", output))\n",
    "            messages.append(HumanMessage(content=\"If you are working on a task, continue. If not, use getNextTask to get the next task.\", additional_kwargs={}, response_metadata={}))        \n",
    "\n",
    "    except EOFError:\n",
    "        user_input = \"Thank you for your service!\"\n",
    "        print(\"User: \" + user_input)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(\"An error occured: \"+str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d921e438-a680-4270-b9bc-c1942f967a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
