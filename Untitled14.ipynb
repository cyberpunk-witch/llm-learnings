{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bad072b-5f0f-4f71-aaae-b1cb5bf92809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"             CL      portland  >      clark/cowlitz  >      community  >      activity partners         post    account       favorites         hidden         CL   clark/cowlitz            >\\n\\nactivity partners   ...       ◀  prev  ▲  next ▶      reply      favorite     favorite       hide     unhide       ⚐  ⚑   flag    ⚑  flagged        Posted 2025-06-18 15:16   Contact Information:    print      Lets go walking/hiking (Vancouver)            QR Code Link to This Post   I am a senior and would like to find another senior or a group to go walking with. I consider myself to be generally fit and would enjoy hikes 45 to 60 minutes long. Prefer paved trails but will consider all.....thanks     post id: 7859242796  posted: 2025-06-18 15:16    ♥ best of   [ ? ]           © 2025 craigslist CL  help  safety  privacy  terms  about  app         loading  reading  writing  saving  searching    refresh the page.      Lets go walking/hiking - activity partners - craigslist  I am a senior and would like to find another senior or a group to go walking with. I consider myself to be generally fit and would enjoy hikes 45 to 60 minutes long. Prefer paved trails but will...   We've detected that JavaScript is not enabled in your browser. You must enable JavaScript to use craigslist.    \"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88826/2103962697.py:14: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n",
      "  texts = soup.findAll(text=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 88\u001b[0m, in \u001b[0;36mscrape\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m(visible_text)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124m        <webpage>\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124m            <url>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</url>\u001b[39m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124m            <title>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo title found\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</title>\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124m            <content>\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mvisible_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m()\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124m            </content>\u001b[39m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124m        </webpage>\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'join'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected error while scraping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn unexpected error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 103\u001b[0m \u001b[43mscrape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://portland.craigslist.org/clk/act/d/vancouver-lets-go-walking-hiking/7859242796.html\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 100\u001b[0m, in \u001b[0;36mscrape\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 100\u001b[0m     \u001b[43mlogger\u001b[49m\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected error while scraping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn unexpected error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts) \n",
    "    return [u\" \".join(t.strip() for t in visible_texts)]\n",
    "\n",
    "def extract_title(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    title = soup.find('title')\n",
    "    return title\n",
    "\n",
    "tokenlen = 30000\n",
    "max_length = 12000\n",
    "# recursion limit\n",
    "recurse = 50\n",
    "\n",
    "def smart_truncate(text: str) -> str:\n",
    "    \"\"\"Intelligently truncate text at natural boundaries\"\"\"\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "    \n",
    "    # Try to cut at paragraph breaks first\n",
    "    truncated = text[:max_length]\n",
    "    \n",
    "    # Find last paragraph break\n",
    "    last_para = truncated.rfind('\\n\\n')\n",
    "    if last_para > max_length * 0.7:  # If we don't lose too much\n",
    "        return truncated[:last_para] + \"\\n\\n[Content truncated at paragraph break...]\"\n",
    "    \n",
    "    # Fallback to sentence breaks\n",
    "    last_sentence = truncated.rfind('. ')\n",
    "    if last_sentence > max_length * 0.8:\n",
    "        return truncated[:last_sentence + 1] + \"\\n\\n[Content truncated...]\"\n",
    "    \n",
    "    # Hard truncate as last resort\n",
    "    return truncated + \"\\n\\n[Content truncated...]\"\n",
    "\n",
    "def scrape(url:str)->str:\n",
    "    \"\"\"\n",
    "    Scrape visible text content from a website URL.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL to scrape. Must be a valid HTTP/HTTPS URL.\n",
    "        \n",
    "    Returns:\n",
    "        str: The visible text content wrapped in <text> tags, or error message.\n",
    "             the text will be truncated if it is too long.\n",
    "        \n",
    "    Example:\n",
    "        >>> scrape(\"https://example.com\")\n",
    "        \"<text>Example Domain This domain is for use in illustrative examples...</text>\"\n",
    "    \n",
    "    Note:\n",
    "        - Only scrapes visible text, not HTML markup\n",
    "        - Has basic error handling for network issues\n",
    "        - Returns content wrapped in XML-style tags for parsing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        with urllib.request.urlopen(url, timeout=30) as response:\n",
    "            html = response.read()\n",
    "            \n",
    "        # Extract title and text\n",
    "        title = extract_title(html)\n",
    "        visible_text = text_from_html(html)\n",
    "        \n",
    "        # Truncate text if too long\n",
    "        visible_text = smart_truncate(visible_text)\n",
    "        print(visible_text)\n",
    "        return f\"\"\"\n",
    "            <webpage>\n",
    "                <url>{url}</url>\n",
    "                <title>{title or \"No title found\"}</title>\n",
    "                <content>\n",
    "                    {visible_text.join().strip()}\n",
    "                </content>\n",
    "            </webpage>\n",
    "            \"\"\"\n",
    "        \n",
    "    except urllib.error.URLError as e:\n",
    "        logger.error(f\"URL error while scraping {url}: {e}\")\n",
    "        return f\"URL error occurred: {e}\"\n",
    "    except urllib.error.HTTPError as e:\n",
    "        logger.error(f\"HTTP error while scraping {url}: {e}\")\n",
    "        return f\"HTTP error occurred: {e.code} - {e.reason}\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error while scraping {url}: {e}\")\n",
    "        return f\"An unexpected error occurred: {e}\"\n",
    "\n",
    "scrape(\"https://portland.craigslist.org/clk/act/d/vancouver-lets-go-walking-hiking/7859242796.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2c7e6-05ff-4e95-a89b-d6f00145c85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
