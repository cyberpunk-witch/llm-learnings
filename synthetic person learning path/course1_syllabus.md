# Course 1: Python & Neural Networks Fundamentals
**Duration**: 6-8 weeks (1 hour/day)  
**Prerequisites**: Basic programming knowledge  
**Goal**: Build solid Python foundation and understand neural networks from first principles

*Curriculum developed in collaboration with Claude (Anthropic) - AI-assisted course design and resource curation*

## Week 1: Python Mastery for ML
**Objective**: Strengthen Python skills for data science and ML work

### Day 1-2: Python Fundamentals Review
- **Study**: [Python.org Tutorial](https://docs.python.org/3/tutorial/) - Focus on chapters 3-5, 8-9
- **Practice**: Complete Python exercises on data structures
- **Project**: Build a simple text analyzer (word count, frequency analysis)

### Day 3-4: NumPy & Scientific Python
- **Study**: [NumPy Quickstart](https://numpy.org/doc/stable/user/quickstart.html)
- **Practice**: Array operations, broadcasting, linear algebra basics
- **Project**: Implement matrix operations from scratch, then compare with NumPy

### Day 5-7: Data Manipulation & Visualization
- **Study**: [Pandas Getting Started](https://pandas.pydata.org/docs/getting_started/index.html)
- **Study**: [Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html)
- **Project**: Load and analyze a dataset, create visualizations

## Week 2: Mathematical Foundations
**Objective**: Build mathematical intuition for neural networks

### Day 8-10: Linear Algebra for ML
- **Study**: [3Blue1Brown Linear Algebra Series](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) (Videos 1-5)
- **Practice**: Khan Academy Linear Algebra exercises
- **Project**: Implement dot product, matrix multiplication, eigenvalue decomposition

### Day 11-14: Calculus & Optimization
- **Study**: [3Blue1Brown Calculus Series](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) (Videos 1-4)
- **Study**: [Gradient Descent Explained](https://towardsdatascience.com/gradient-descent-algorithm-and-its-variants-10f652806a3)
- **Project**: Implement gradient descent from scratch for simple function optimization

## Week 3: Neural Networks from Scratch
**Objective**: Understand neural networks at the implementation level

### Day 15-17: Perceptron & Single Layer Networks
- **Study**: [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap1.html) - Chapter 1
- **Practice**: Implement perceptron for binary classification
- **Project**: Build AND, OR, XOR gates with perceptrons

### Day 18-21: Multi-Layer Networks & Backpropagation
- **Study**: [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap2.html) - Chapter 2
- **Study**: [Backpropagation Calculus](https://www.youtube.com/watch?v=Ilg3gGewQ5U) (3Blue1Brown)
- **Project**: Implement multi-layer perceptron with backpropagation from scratch

## Week 4: Introduction to Deep Learning Frameworks
**Objective**: Learn to use modern ML frameworks effectively

### Day 22-24: PyTorch Fundamentals
- **Study**: [PyTorch Tutorials](https://pytorch.org/tutorials/beginner/basics/intro.html)
- **Practice**: Tensors, autograd, building simple models
- **Project**: Recreate your from-scratch neural network in PyTorch

### Day 25-28: Training Deep Networks
- **Study**: [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) - Course 1, Week 2-3 (audit for free)
- **Practice**: Optimization, regularization, hyperparameter tuning
- **Project**: Train a neural network on a real dataset (start with digits/iris)

## Week 5: Computer Vision Basics
**Objective**: Apply neural networks to image processing

### Day 29-31: Image Processing Fundamentals
- **Study**: [OpenCV Python Tutorial](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html) - Basic operations
- **Practice**: Image loading, filtering, transformations
- **Project**: Build image preprocessing pipeline

### Day 32-35: Convolutional Neural Networks
- **Study**: [CS231n Convolutional Neural Networks](http://cs231n.github.io/convolutional-networks/)
- **Study**: [CNN Explainer](https://poloclub.github.io/cnn-explainer/) (Interactive)
- **Project**: Implement simple CNN for image classification

## Week 6: Practical Projects
**Objective**: Build complete ML applications

### Day 36-38: Handwriting Recognition
- **Study**: MNIST dataset exploration
- **Project**: Build handwriting recognition system using CNN
- **Evaluation**: Achieve >95% accuracy on MNIST

### Day 39-42: Mini-Project Integration
- **Project**: Create a simple image classifier for your own dataset
- **Extension**: Add data augmentation and model evaluation
- **Documentation**: Write up your approach and results

## Resources & Tools

### Essential Tools
- **Python**: 3.8+
- **Libraries**: NumPy, Pandas, Matplotlib, PyTorch, OpenCV
- **Environment**: Jupyter notebooks or VS Code
- **Version Control**: Git for project tracking

### Additional Resources
- **Books**: 
  - "Hands-On Machine Learning" by Aurélien Géron
  - "Deep Learning" by Ian Goodfellow (reference)
- **Online Courses**:
  - Fast.ai Practical Deep Learning
  - CS231n Stanford (video lectures)
- **Practice Platforms**:
  - Kaggle Learn
  - Google Colab for experimentation

## Assessment & Milestones

### Week 2 Checkpoint
- Can implement basic linear algebra operations
- Understands gradient descent conceptually and practically

### Week 4 Checkpoint  
- Can build and train neural networks from scratch
- Comfortable with PyTorch basics

### Final Project
- Complete handwriting recognition system
- Demonstration of understanding through code comments and documentation
- Ability to explain design decisions and trade-offs

## Preparation for Course 2
By the end of this course, you should be ready to tackle:
- Advanced neural architectures
- Memory systems and attention mechanisms
- Multi-modal processing
- Agent-based architectures

## Daily Schedule Template
- **15 min**: Review previous day's concepts
- **30 min**: New material study
- **15 min**: Hands-on coding/practice

## Success Indicators
- Can implement neural networks without looking up basic operations
- Understands the mathematical foundations of backpropagation
- Can debug and improve model performance systematically
- Comfortable reading and implementing ML papers' basic concepts