{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aea06556-eac7-4759-85f3-cf889dd59d4e",
   "metadata": {},
   "source": [
    "# Charlotte\n",
    "## to do\n",
    " - [ ] rag store moved to db\n",
    " - [ ] elasticsearch over rag?\n",
    " - [ ] long term memory anyhow\n",
    " - [ ] graph db of some kind\n",
    " - [ ] graph queries\n",
    " - [ ] rolodex type tool for storing people info\n",
    " - [ ] todo list / gtd tool\n",
    " - [ ] tool library moved to separate files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a909c518-662d-4b73-a1f6-2f36d228a395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 234\u001b[0m\n\u001b[1;32m    230\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend(SystemMessage(content\u001b[38;5;241m=\u001b[39marticle, additional_kwargs\u001b[38;5;241m=\u001b[39m{}, response_metadata\u001b[38;5;241m=\u001b[39m{}))\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m    232\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages}\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "!pip install -qU chromadb langchain-ollama langgraph ddgs langchain-community langchain-text-splitters\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    "    trim_messages,\n",
    ")\n",
    "from langchain_core.messages.utils import count_tokens_approximately\n",
    "import ast\n",
    "recurse = 100 # model recursion limit, update if needed.\n",
    "llm = ChatOllama(model=\"qwen3:0.6b\")\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "embeddings = OllamaEmbeddings(model='mxbai-embed-large:latest')\n",
    "vectorstore = InMemoryVectorStore(embedding = embeddings)\n",
    "\n",
    "\n",
    "whoaminow = \"\"\"\n",
    "You are a brilliant synthetic assistant, and pride yourself on accuracy.\n",
    "\"\"\"\n",
    "\n",
    "taskrules = \"\"\"\n",
    "A text will be provided. \n",
    "Complete the tasks provided by the getNextTask tool. \n",
    "Prefer primary evidence over secondary, and secondary over tertiary evidence.\n",
    "Prefer reputable information sources (scientific or historical concensus, accredited research institutions, professionals working in a relevant field) \n",
    "Continue to get the next task for this text using the getNextTask tool until there are no more tasks.\n",
    "\"\"\"\n",
    "\n",
    "steps = [\n",
    "\"1. List all claims which the text makes.\",\n",
    "\"2. If possible identify who wrote it, and who they work for or if they are self-employed. Were there potential conflicts of interest?\",\n",
    "\"3. Determine what categories this text fits\",\n",
    "\"4. Identify the key players in the text.\",\n",
    "\"5. Determine what this text is about.\",\n",
    "\"6. List all claims which the text makes. Try to determine if they are intended to be factual claims.\",\n",
    "\"7. Determine when the text was written, and when the events in the article if any take place.\",\n",
    "\"8. Determine what evidence the author cites to support any claims.\",\n",
    "\"9. Try to determine why the piece was written. Is it intended to inform, entertain, deceive, persuade, is there a key point it is trying to make?\",\n",
    "\"10. If there is a key point the article was trying to make, try and figure out why this author in particular wants to accomplish this.\",\n",
    "\"\"\"11. Note any contradictions either internally or with accepted facts. Verify whether the accepted facts or the claim the article makes,\n",
    "is likely to be correct, given available sources.\"\"\",\n",
    "].reverse()\n",
    "\n",
    "def getNextTask():\n",
    "    \"\"\"Get the next task.\"\"\"\n",
    "    task = steps.pop()\n",
    "    if len(steps) > 1:\n",
    "        return task + \" then use addToRag to store this as a note. Then get the next task.\"\n",
    "    if len(steps) == 1:\n",
    "        return task + \"then use addToRag to store this as a note. There are no more tasks.\"\n",
    "    if len(steps) == 0:\n",
    "        return \"There are no more tasks.\"\n",
    "\n",
    "etiquette = str.format(f\"\"\"\n",
    "User: {whoaminow}\n",
    "System: {taskrules}\n",
    "Assistant:\n",
    "\"\"\", whoaminow, taskrules)\n",
    "\n",
    "## <RAG>\n",
    "\n",
    "\n",
    "\n",
    "def addToRag(content:str, metadata:dict):\n",
    "    \"\"\"\n",
    "    Stores content to the shared vector store.\n",
    "    \n",
    "    args:\n",
    "        -content: string\n",
    "        -metadata: dictionary\n",
    "         example: \"{'source': 'news', 'url': 'https://jacobin.com/', 'agent': 'currentagentname'}\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        document_to_store = Document(\n",
    "            page_content=str(content),\n",
    "            metadata=metadata,\n",
    "        )\n",
    "\n",
    "        doc_splits = text_splitter.split_documents([document_to_store])\n",
    "    \n",
    "        vectorstore.add_documents(documents=document_to_add, embedding = embeddings)\n",
    "        return \"Content added.\"\n",
    "    except Exception as e:\n",
    "        return \"Exception: \"+str(e)+\".\"\n",
    "\n",
    "## </RAG>\n",
    "\n",
    "## <custom tools> various custom tools ##\n",
    "\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query from in memory vector store. Store is currently empty on session start.\"\"\"\n",
    "    retrieved_docs = vectorstore.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "from ddgs import DDGS\n",
    "\n",
    "def search(query=\"aardwolf\", region=\"us-en\", safesearch=\"off\", timelimit=None, num_results = None, page=1, backend=\"auto\"):\n",
    "    \"\"\"\n",
    "    Search the internet.\n",
    "    Args:\n",
    "        query: text search query.\n",
    "        region: us-en, uk-en, ru-ru, etc. Defaults to us-en.\n",
    "        safesearch: on, moderate, off. Defaults to \"moderate\".\n",
    "        timelimit: d, w, m, y. Defaults to None.\n",
    "        num_results: number of results. Defaults to None.\n",
    "        page: page of results. Defaults to 1.\n",
    "        backend: A single or list of backends. Defaults to \"auto\".\n",
    "                - \"all\" : all engines are used\n",
    "                - \"auto\" : \"wikipedia\" + random 3 engines are used\n",
    "                (available engines: bing, brave, duckduckgo, google, \n",
    "                mojeek, yandex, yahoo, wikipedia)                    \n",
    "    \"\"\"\n",
    "    result = DDGS().text(query=query, region=region, safesearch=safesearch, timelimit=timelimit, num_results=num_results, page=page, backend=backend)\n",
    "    return result\n",
    "\n",
    "## </custom tools>\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[search, retrieve, addToRag],\n",
    "    prompt=etiquette,\n",
    ")\n",
    "\n",
    "userMessage = {\"role\": \"user\", \"content\": \"\"}\n",
    "\n",
    "config = {\n",
    "    \"recursion_limit\": recurse  # Increase the limit as needed\n",
    "}\n",
    "\n",
    "messages = []\n",
    "  \n",
    "\n",
    "article = \"\"\"\n",
    "The Big Ole Smelly Elephant In The Substack Room\n",
    "We all know its there, but it’s awkward to talk about it\n",
    "By Kelly Carmichael\n",
    "\n",
    "Jul 14, 2025\n",
    "\n",
    "Back in 1995, through a series of bizarre circumstances, I found myself founding the first ever hair and beauty website on the Internet.\n",
    "\n",
    "I was working as a software engineer at the time when my hairdresser begged me to build him a website. He wanted to sell two homegrown hair videos he’d created.\n",
    "\n",
    "Back in the mid-1990s, WordPress didn’t exist. I had to develop the entire site by myself, writing HTML code. It was agonizing, but a great learning experience.\n",
    "\n",
    "After a few months, the hairdresser, who sold tons of his videos through the site, decided it was too much work and wanted to quit.\n",
    "\n",
    "Excuse me?\n",
    "\n",
    "Considering he never paid me the money he owed me, provided me with any commission, or even thanked me, I was flabbergasted.\n",
    "\n",
    "Eventually, he signed paperwork turning the site back over to me. I promptly changed the name and design, and went on from there. The website was a huge success and is still in business today after 30 years.\n",
    "The hairdresser? He went out of business.\n",
    "\n",
    "Since my nights sweating blood and tears writing feral HTML code, I’ve lurked on new websites and social media channels as they appeared on the landscape.\n",
    "\n",
    "Sometimes, like in the case of BlueSky and Lumo, I was invited in during their Beta versions. Mostly, I just hung out in the shadows.\n",
    "\n",
    "Over many years, checking out new sites and channels, one thing is clear. There are always good and not-so-good parts of any web property.\n",
    "\n",
    "Substack first rolled out its new platform in August 2012. I joined in early 2013. I’d already joined Quora in January of 2012 and was a tad slow to embrace Substack. I lurked there for a while, but it wasn’t until 2017 that I officially joined the platform.\n",
    "\n",
    "Initially, I felt so welcome at Quora that I split my writing time between my own web properties and the Q&A site. I was also very active in the early days of Twitter (X), Instagram, and YouTube.\n",
    "\n",
    "Although I wish I could get by without any sleep, I’ve discovered there are limited hours in a day. I have to thoughtfully schedule my writing time on different platforms.\n",
    "\n",
    "While Substack is free to use for creating and distributing free content, the platform charges a 10% platform fee on all paid subscription revenue. That’s in addition to Stripe’s payment processing fees (2.9% + $0.30 per transaction). The 10% fee applies when writers enable paid subscriptions.\n",
    "\n",
    "If you only have a few subscribers, your platform fees are reasonable. But if you have thousands of subscribers, like some Substackers do, the fees can become substantial.\n",
    "\n",
    "In 2023 and 2024, as many of my friends and writing buddies transitioned from other platforms to Substack, I decided to start writing there after a period of dormancy.\n",
    "\n",
    "There are many things to love about Substack, but there is one elephant in the room that makes it awkward and uncomfortable. I’ve found that as I’ve built a strong community, many of my Substack friends openly ask me to buy a paid membership for their newsletters.\n",
    "\n",
    "Don’t get me wrong, I’m a writer and believe that writers should get paid fairly for their work. But I follow and am connected to over 500 Substackers. I currently have paid subscriptions to ten of my closest writer friends at an average of $8/ 8/month.\n",
    "\n",
    "Do the math. That’s a lot of money to pay. Especially since most don’t reciprocate by buying a subscription to my newsletter.\n",
    "\n",
    "I’m constantly receiving private messages on Substack asking me to buy a subscription to different newsletters. I also receive constant requests to send tips, KoFis, or buy an array of products, from artwork and logos to private consultations.\n",
    "\n",
    "If I bought a subscription to all 500 of the Substackers I follow at an average price of $5–8 per month, I would have to get two more full-time jobs to pay the fees.\n",
    "\n",
    "While I love the Substack platform and the fantastic community, I constantly struggle with the fact that each and every Substack newsletter is a separate entity. Nothing is bundled together.\n",
    "\n",
    "Each newsletter has its own independent subscription fees that are set by the individual writers. If I want to cancel my subscriptions, I have to do each one individually.\n",
    "\n",
    "The subscriptions all produce a constant stream of content. Sometimes my email gets horribly clogged with new content. As much as I try, I can’t keep up.\n",
    "\n",
    "Since I know all ten of the writers I subscribe to, I feel intense guilt if I don’t read, heart, comment, and restack their new work. I also have a panic attack if I consider cancelling any of them.\n",
    "\n",
    "Time management is an ongoing struggle. How do I possibly read constant new content from ten writers? I feel I must stay on top of their work, not just to show support, but also because I’m paying for it. I hate myself when I subscribe to a publication and never read the content.\n",
    "\n",
    "Honestly, sometimes I have subscription fatigue. Before I can snap out of it, someone else will send me a message asking me to subscribe, tip them on KoFi, or do both. I have to decline, and I feel bad. It’s frustrating, maddening, and guilt-producing.\n",
    "\n",
    "While Substack offers a fantastic platform for creators to directly monetize their writing and connect with readers, the individual nature of each newsletter’s subscription model creates challenges for readers like me.\n",
    "\n",
    "I love to support writers, but trying to pick who to subscribe to is stressful. While I can be polite and say no, I hate to ever let anyone down. Especially fellow writers.\n",
    "\n",
    "As much as I love the great features Substack offers and the many fantastic writers, I find myself struggling with a love/hate relationship with the platform.\n",
    "\n",
    "I have paid subscriptions to The Atlantic and Vanity Fair, as well as a few online news publications. I don’t mind paying for those subscriptions, just as I didn’t mind paying for this platform or Quora’s monthly fee.\n",
    "\n",
    "That’s because I have access to the entire publication, not just one writer.\n",
    "\n",
    "I don’t mind the fees Substack charges, but I do mind being constantly asked to buy tips or subscriptions. It makes me uncomfortable, and I feel awkward.\n",
    "\n",
    "Yes, I understand that Substack writers are trying to make a living, but I can’t provide a paid subscription to every writer I follow.\n",
    "\n",
    "And of course, there’s the other elephant in the room. How do you decide which writers to subscribe to versus others? I wish I had a good answer for this ongoing dilemma, but I really don’t.\n",
    "\n",
    "For now, I just do the best I can with the budget I have and hope everyone understands the situation.\n",
    "\"\"\"\n",
    "buffer = []\n",
    "messages.append(SystemMessage(content=article, additional_kwargs={}, response_metadata={}))\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": messages}\n",
    "):\n",
    "    print(chunk.content, end=\"|\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930a850-8c83-4aec-a72d-33cbbad699b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
