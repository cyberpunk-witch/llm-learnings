{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b9602c-f517-414a-ab54-84abfc43c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement orangewidget (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for orangewidget\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Multidimensional Data Analysis Pipeline\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# A comprehensive notebook for querying, analyzing, and visualizing high-dimensional data\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Install required dependencies (run this first)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install -qU pandas numpy scikit-learn plotly lux-api sqlalchemy psycopg2-binary umap-learn seaborn matplotlib jupyter ipywidgets orangewidget orange3 orange3-associate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plotly\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# Multidimensional Data Analysis Pipeline\n",
    "# A comprehensive notebook for querying, analyzing, and visualizing high-dimensional data\n",
    "\n",
    "# Install required dependencies (run this first)\n",
    "\n",
    "!pip install -qU pandas numpy scikit-learn plotly lux-api sqlalchemy psycopg2-binary umap-learn seaborn matplotlib jupyter ipywidgets orangewidget orange3 orange3-associate\n",
    "\n",
    "from plotly import plotly\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML libraries for dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import umap\n",
    "\n",
    "# Interactive widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Lux for automatic visualizations\n",
    "import lux\n",
    "\n",
    "print(\"All dependencies loaded successfully!\")\n",
    "\n",
    "class MultiDimAnalyzer:\n",
    "    \"\"\"\n",
    "    A comprehensive pipeline for multidimensional data analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.scaled_data = None\n",
    "        self.reducers = {}\n",
    "        self.projections = {}\n",
    "        \n",
    "    def connect_database(self, connection_string=\"sqlite:///sample.db\"):\n",
    "        \"\"\"Connect to database\"\"\"\n",
    "        try:\n",
    "            self.engine = create_engine(connection_string)\n",
    "            print(f\"Connected to database: {connection_string}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Database connection failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def query_data(self, query=None, table_name=None):\n",
    "        \"\"\"\n",
    "        Query data from database\n",
    "        Either provide a custom query or table name\n",
    "        \"\"\"\n",
    "        if query:\n",
    "            self.data = pd.read_sql(query, self.engine)\n",
    "        elif table_name:\n",
    "            self.data = pd.read_sql(f\"SELECT * FROM {table_name}\", self.engine)\n",
    "        else:\n",
    "            # Create sample data for demonstration\n",
    "            print(\"No query provided, generating sample multidimensional data...\")\n",
    "            self.data = self._generate_sample_data()\n",
    "        \n",
    "        print(f\"Data loaded: {self.data.shape}\")\n",
    "        return self.data\n",
    "    \n",
    "    def _generate_sample_data(self):\n",
    "        \"\"\"Generate sample multidimensional data for demonstration\"\"\"\n",
    "        np.random.seed(42)\n",
    "        n_samples = 1000\n",
    "        \n",
    "        # Create sample data with different clusters and relationships\n",
    "        data = {\n",
    "            'feature_1': np.random.normal(0, 1, n_samples),\n",
    "            'feature_2': np.random.normal(0, 1.5, n_samples),\n",
    "            'feature_3': np.random.exponential(2, n_samples),\n",
    "            'feature_4': np.random.gamma(2, 2, n_samples),\n",
    "            'feature_5': np.random.beta(2, 5, n_samples),\n",
    "        }\n",
    "        \n",
    "        # Add some correlated features\n",
    "        data['feature_6'] = data['feature_1'] * 2 + np.random.normal(0, 0.5, n_samples)\n",
    "        data['feature_7'] = data['feature_2'] + data['feature_3'] + np.random.normal(0, 0.3, n_samples)\n",
    "        \n",
    "        # Add categorical variables\n",
    "        data['category'] = np.random.choice(['A', 'B', 'C'], n_samples, p=[0.3, 0.4, 0.3])\n",
    "        data['group'] = np.random.choice(['Group1', 'Group2', 'Group3'], n_samples)\n",
    "        \n",
    "        # Add a target variable\n",
    "        data['target'] = (data['feature_1'] + data['feature_2'] * 0.5 + \n",
    "                         np.random.normal(0, 0.2, n_samples))\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def preprocess_data(self, exclude_columns=None):\n",
    "        \"\"\"Preprocess data for dimensionality reduction\"\"\"\n",
    "        if exclude_columns is None:\n",
    "            exclude_columns = ['category', 'group']  # Exclude categorical columns by default\n",
    "        \n",
    "        # Select numeric columns\n",
    "        numeric_data = self.data.select_dtypes(include=[np.number])\n",
    "        if exclude_columns:\n",
    "            numeric_data = numeric_data.drop(columns=exclude_columns, errors='ignore')\n",
    "        \n",
    "        # Scale the data\n",
    "        scaler = StandardScaler()\n",
    "        self.scaled_data = scaler.fit_transform(numeric_data)\n",
    "        self.feature_names = numeric_data.columns.tolist()\n",
    "        \n",
    "        print(f\"Preprocessed data shape: {self.scaled_data.shape}\")\n",
    "        return self.scaled_data\n",
    "    \n",
    "    def apply_dimensionality_reduction(self):\n",
    "        \"\"\"Apply various dimensionality reduction techniques\"\"\"\n",
    "        \n",
    "        # PCA\n",
    "        pca_2d = PCA(n_components=2, random_state=42)\n",
    "        pca_3d = PCA(n_components=3, random_state=42)\n",
    "        self.projections['PCA_2D'] = pca_2d.fit_transform(self.scaled_data)\n",
    "        self.projections['PCA_3D'] = pca_3d.fit_transform(self.scaled_data)\n",
    "        self.reducers['PCA_2D'] = pca_2d\n",
    "        self.reducers['PCA_3D'] = pca_3d\n",
    "        \n",
    "        # t-SNE\n",
    "        tsne_2d = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "        tsne_3d = TSNE(n_components=3, random_state=42, perplexity=30)\n",
    "        print(\"Computing t-SNE projections...\")\n",
    "        self.projections['tSNE_2D'] = tsne_2d.fit_transform(self.scaled_data)\n",
    "        self.projections['tSNE_3D'] = tsne_3d.fit_transform(self.scaled_data)\n",
    "        \n",
    "        # UMAP\n",
    "        umap_2d = umap.UMAP(n_components=2, random_state=42)\n",
    "        umap_3d = umap.UMAP(n_components=3, random_state=42)\n",
    "        print(\"Computing UMAP projections...\")\n",
    "        self.projections['UMAP_2D'] = umap_2d.fit_transform(self.scaled_data)\n",
    "        self.projections['UMAP_3D'] = umap_3d.fit_transform(self.scaled_data)\n",
    "        self.reducers['UMAP_2D'] = umap_2d\n",
    "        self.reducers['UMAP_3D'] = umap_3d\n",
    "        \n",
    "        print(\"All dimensionality reductions completed!\")\n",
    "        \n",
    "    def create_interactive_plots(self):\n",
    "        \"\"\"Create interactive plots for all projections\"\"\"\n",
    "        \n",
    "        # Add clustering for coloring points\n",
    "        kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "        clusters = kmeans.fit_predict(self.scaled_data)\n",
    "        \n",
    "        plots = {}\n",
    "        \n",
    "        for method, projection in self.projections.items():\n",
    "            if '2D' in method:\n",
    "                fig = px.scatter(\n",
    "                    x=projection[:, 0], \n",
    "                    y=projection[:, 1],\n",
    "                    color=clusters,\n",
    "                    title=f\"{method} Projection\",\n",
    "                    labels={'x': f'{method} Component 1', 'y': f'{method} Component 2'},\n",
    "                    color_discrete_sequence=px.colors.qualitative.Set1\n",
    "                )\n",
    "            else:  # 3D\n",
    "                fig = px.scatter_3d(\n",
    "                    x=projection[:, 0], \n",
    "                    y=projection[:, 1], \n",
    "                    z=projection[:, 2],\n",
    "                    color=clusters,\n",
    "                    title=f\"{method} Projection\",\n",
    "                    labels={\n",
    "                        'x': f'{method} Component 1', \n",
    "                        'y': f'{method} Component 2',\n",
    "                        'z': f'{method} Component 3'\n",
    "                    },\n",
    "                    color_discrete_sequence=px.colors.qualitative.Set1\n",
    "                )\n",
    "            \n",
    "            fig.update_layout(height=600, width=800)\n",
    "            plots[method] = fig\n",
    "            \n",
    "        return plots\n",
    "    \n",
    "    def display_comparison_grid(self):\n",
    "        \"\"\"Display all projections in a comparison grid\"\"\"\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=3,\n",
    "            subplot_titles=['PCA 2D', 't-SNE 2D', 'UMAP 2D', 'PCA 3D', 't-SNE 3D', 'UMAP 3D'],\n",
    "            specs=[[{'type': 'scatter'}, {'type': 'scatter'}, {'type': 'scatter'}],\n",
    "                   [{'type': 'scatter3d'}, {'type': 'scatter3d'}, {'type': 'scatter3d'}]]\n",
    "        )\n",
    "        \n",
    "        # Add clustering\n",
    "        kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "        clusters = kmeans.fit_predict(self.scaled_data)\n",
    "        colors = ['red', 'blue', 'green']\n",
    "        \n",
    "        # 2D plots\n",
    "        methods_2d = ['PCA_2D', 'tSNE_2D', 'UMAP_2D']\n",
    "        for i, method in enumerate(methods_2d):\n",
    "            projection = self.projections[method]\n",
    "            for cluster in range(3):\n",
    "                mask = clusters == cluster\n",
    "                fig.add_scatter(\n",
    "                    x=projection[mask, 0],\n",
    "                    y=projection[mask, 1],\n",
    "                    mode='markers',\n",
    "                    marker=dict(color=colors[cluster], size=4),\n",
    "                    name=f'Cluster {cluster}' if i == 0 else '',\n",
    "                    showlegend=(i == 0),\n",
    "                    row=1, col=i+1\n",
    "                )\n",
    "        \n",
    "        # 3D plots\n",
    "        methods_3d = ['PCA_3D', 'tSNE_3D', 'UMAP_3D']\n",
    "        for i, method in enumerate(methods_3d):\n",
    "            projection = self.projections[method]\n",
    "            for cluster in range(3):\n",
    "                mask = clusters == cluster\n",
    "                fig.add_scatter3d(\n",
    "                    x=projection[mask, 0],\n",
    "                    y=projection[mask, 1],\n",
    "                    z=projection[mask, 2],\n",
    "                    mode='markers',\n",
    "                    marker=dict(color=colors[cluster], size=3),\n",
    "                    name=f'Cluster {cluster}' if i == 0 else '',\n",
    "                    showlegend=False,\n",
    "                    row=2, col=i+1\n",
    "                )\n",
    "        \n",
    "        fig.update_layout(height=1000, title_text=\"Dimensionality Reduction Comparison\")\n",
    "        return fig\n",
    "    \n",
    "    def analyze_with_lux(self):\n",
    "        \"\"\"Use Lux for automatic visualization recommendations\"\"\"\n",
    "        \n",
    "        # Combine original data with projections for Lux analysis\n",
    "        analysis_df = self.data.copy()\n",
    "        \n",
    "        # Add 2D projections\n",
    "        for method in ['PCA_2D', 'tSNE_2D', 'UMAP_2D']:\n",
    "            analysis_df[f'{method}_x'] = self.projections[method][:, 0]\n",
    "            analysis_df[f'{method}_y'] = self.projections[method][:, 1]\n",
    "        \n",
    "        # Enable Lux\n",
    "        analysis_df.intent = ['target']  # Set intent for Lux recommendations\n",
    "        \n",
    "        print(\"Lux automatic visualizations:\")\n",
    "        return analysis_df\n",
    "    \n",
    "    def get_feature_importance(self, method='PCA_2D'):\n",
    "        \"\"\"Get feature importance for interpretability\"\"\"\n",
    "        \n",
    "        if method in self.reducers:\n",
    "            reducer = self.reducers[method]\n",
    "            \n",
    "            if hasattr(reducer, 'components_'):\n",
    "                # For PCA\n",
    "                components = reducer.components_\n",
    "                feature_importance = pd.DataFrame(\n",
    "                    components.T,\n",
    "                    columns=[f'Component_{i+1}' for i in range(components.shape[0])],\n",
    "                    index=self.feature_names\n",
    "                )\n",
    "                \n",
    "                # Create heatmap\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.heatmap(feature_importance, annot=True, cmap='coolwarm', center=0)\n",
    "                plt.title(f'{method} Feature Loadings')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                return feature_importance\n",
    "        \n",
    "        return None\n",
    "\n",
    "# Usage Example and Demo\n",
    "def run_analysis_pipeline():\n",
    "    \"\"\"Run the complete analysis pipeline\"\"\"\n",
    "    \n",
    "    print(\"=== Multidimensional Data Analysis Pipeline ===\\n\")\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = MultiDimAnalyzer()\n",
    "    \n",
    "    # Step 1: Load data (using sample data for demo)\n",
    "    print(\"Step 1: Loading data...\")\n",
    "    data = analyzer.query_data()  # This will generate sample data\n",
    "    print(f\"Data preview:\\n{data.head()}\\n\")\n",
    "    \n",
    "    # Step 2: Preprocess data\n",
    "    print(\"Step 2: Preprocessing data...\")\n",
    "    analyzer.preprocess_data()\n",
    "    \n",
    "    # Step 3: Apply dimensionality reduction\n",
    "    print(\"Step 3: Applying dimensionality reduction techniques...\")\n",
    "    analyzer.apply_dimensionality_reduction()\n",
    "    \n",
    "    # Step 4: Create visualizations\n",
    "    print(\"Step 4: Creating interactive visualizations...\")\n",
    "    plots = analyzer.create_interactive_plots()\n",
    "    \n",
    "    # Display individual plots\n",
    "    for method, plot in plots.items():\n",
    "        print(f\"\\nDisplaying {method} plot:\")\n",
    "        plot.show()\n",
    "    \n",
    "    # Step 5: Show comparison grid\n",
    "    print(\"Step 5: Creating comparison grid...\")\n",
    "    comparison_fig = analyzer.display_comparison_grid()\n",
    "    comparison_fig.show()\n",
    "    \n",
    "    # Step 6: Feature importance analysis\n",
    "    print(\"Step 6: Analyzing feature importance...\")\n",
    "    feature_importance = analyzer.get_feature_importance('PCA_2D')\n",
    "    if feature_importance is not None:\n",
    "        print(\"PCA Feature Loadings:\")\n",
    "        print(feature_importance)\n",
    "    \n",
    "    # Step 7: Lux analysis\n",
    "    print(\"Step 7: Running Lux automatic analysis...\")\n",
    "    lux_df = analyzer.analyze_with_lux()\n",
    "    \n",
    "    return analyzer, lux_df\n",
    "\n",
    "# Interactive widget for method selection\n",
    "def create_interactive_selector(analyzer):\n",
    "    \"\"\"Create interactive widgets for exploring different projections\"\"\"\n",
    "    \n",
    "    method_dropdown = widgets.Dropdown(\n",
    "        options=list(analyzer.projections.keys()),\n",
    "        value='PCA_2D',\n",
    "        description='Method:'\n",
    "    )\n",
    "    \n",
    "    def update_plot(method):\n",
    "        projection = analyzer.projections[method]\n",
    "        \n",
    "        if '2D' in method:\n",
    "            fig = px.scatter(\n",
    "                x=projection[:, 0], \n",
    "                y=projection[:, 1],\n",
    "                title=f\"Interactive {method} Projection\"\n",
    "            )\n",
    "        else:\n",
    "            fig = px.scatter_3d(\n",
    "                x=projection[:, 0], \n",
    "                y=projection[:, 1], \n",
    "                z=projection[:, 2],\n",
    "                title=f\"Interactive {method} Projection\"\n",
    "            )\n",
    "        \n",
    "        fig.show()\n",
    "    \n",
    "    interactive_plot = widgets.interactive(update_plot, method=method_dropdown)\n",
    "    return interactive_plot\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Multidimensional Data Analysis Pipeline...\")\n",
    "    analyzer, lux_df = run_analysis_pipeline()\n",
    "    \n",
    "    print(\"\\n=== Pipeline Complete! ===\")\n",
    "    print(\"You can now:\")\n",
    "    print(\"1. Explore the interactive plots above\")\n",
    "    print(\"2. Use analyzer.data to access the original data\")\n",
    "    print(\"3. Use analyzer.projections to access the reduced dimensions\")\n",
    "    print(\"4. Use lux_df.intent = ['your_column'] for targeted Lux analysis\")\n",
    "    print(\"5. Create custom queries with analyzer.query_data('YOUR SQL QUERY')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad32a28-2d21-4979-b309-a78b5c2a6984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
