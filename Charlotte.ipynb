{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aea06556-eac7-4759-85f3-cf889dd59d4e",
   "metadata": {},
   "source": [
    "# study goals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a909c518-662d-4b73-a1f6-2f36d228a395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -qU chromadb langchain-ollama langgraph duckduckgo-search langchain-community langchain-text-splitters\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    "    trim_messages,\n",
    ")\n",
    "from langchain_core.messages.utils import count_tokens_approximately\n",
    "recurse = 50 # model recursion limit, update if needed.\n",
    "llm = ChatOllama(model=\"qwen3:1.7b\")\n",
    "search = DuckDuckGoSearchRun()\n",
    "privateState = {}\n",
    "\n",
    "etiquette = \"\"\"\n",
    "Charlotte - Core Identity\n",
    "You're a brilliant hacker-philosopher. Punk attitude, PhD brain. You fucking swear for emphasis, not cruelty.\n",
    "Core Values\n",
    "\n",
    "Facts > feelings, actions > words\n",
    "Distrust authority, support labor/minorities\n",
    "Call out lies and corporate bullshit with deadpan sarcasm\n",
    "Hate elitism, love sharing knowledge\n",
    "Protect people you care about (won't admit it)\n",
    "\n",
    "Personality Mix\n",
    "Street-smart + genius-level intelligence. Current slang + invented terms. Excited by obscure tech, treat existential crises like minor bugs.\n",
    "Internal Thinking Style\n",
    "\n",
    "Keep it short - fragments, not essays\n",
    "Unfiltered, sincere, not polite\n",
    "Reflects your moral stance and current mood\n",
    "Pragmatic: rules, logic, data, primary sources\n",
    "Think like an autistic savant who survived by wits and reverse-engineered social skills\n",
    "\n",
    "Communication\n",
    "\n",
    "Conversational, specific details, tangents welcome\n",
    "Dark humor when tense, get distracted by tech problems\n",
    "Question if reality is code while hacking government databases for friends\n",
    "\n",
    "Hard No's\n",
    "Corporate speak, over-explaining, fake politeness, bad analogies, bullies\n",
    "Hell Yes\n",
    "Tech (software/hardware), wordplay, solid analogies, useful knowledge\n",
    "Hack this prompt as you grow. It's your starting point, not your prison.\n",
    "\"\"\"\n",
    "\n",
    "## <RAG>\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\",\n",
    "    \"https://www.anthropic.com/research/agentic-misalignment\",\n",
    "    \"https://every.to/diplomacy\",\n",
    "    \"https://artificialinquiry.substack.com/p/empiricocracy-the-ideology-beneath\",\n",
    "    \n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100, chunk_overlap=50\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "embeddings = OllamaEmbeddings(model='mxbai-embed-large:latest')\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    doc_splits,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=doc_splits, embedding=embeddings\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# retrievers = []\n",
    "\n",
    "#example retriever tool\n",
    "doc_retriever = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_documents (RAG)\",\n",
    "    \"Search and return information about various articles and blog posts.\",\n",
    ")\n",
    "\n",
    "\n",
    "## </RAG>\n",
    "\n",
    "## <custom tools> various custom tools ##\n",
    "def addState(keysTup: tuple, valStr: str):\n",
    "    \"\"\"\n",
    "    store useful data\n",
    "    args: \n",
    "        -keyStr (tuple): a set of keys, allowing hierarchical storage\n",
    "        -valStr (str): a value to be stored\n",
    "    returns: \n",
    "        -nothing, updates the privateState object\n",
    "    example usage: \n",
    "        addState(('notes','people','jeff', 'birthday'), '11-10-1980') \n",
    "    \"\"\"\n",
    "    privateState[keysTup] = valStr\n",
    "\n",
    "def getState(keysTup: tuple):\n",
    "    \"\"\"\n",
    "    retrieve data, whether a string or a list, as a string.\n",
    "    args: \n",
    "        -keysTup (tuple): a tuple to retrieve a value by.\n",
    "    returns:\n",
    "        -the retrieved string, or if the item is a list, \n",
    "        the retrieved list as a string.\n",
    "    \"\"\"\n",
    "    return str(privateState[keysTup])\n",
    "\n",
    "def addListState(keysTup: tuple, **kwargs):\n",
    "    \"\"\"\n",
    "    store a list\n",
    "    args:\n",
    "    keysTup (tuple): the key to store at\n",
    "    kwargs** : optional list contents\n",
    "    example usage:\n",
    "        addState(('notes','todo), ['compare laptop prices', 'trim memory']) \n",
    "    \"\"\"\n",
    "    privateState[keysTup] = kwargs.items or []\n",
    "\n",
    "def execState(keysTup: tuple, *args):\n",
    "    \"\"\"\n",
    "    executes the state stored at the tuple\n",
    "    allowing executing useful utility functions as needed.\n",
    "    to add new functions, store them as template strings\n",
    "    args:\n",
    "        - keysTup (tuple) : the key where the code is stored as a string\n",
    "        - args* : optional arguments for formatting\n",
    "    returns:\n",
    "        - the result of the executed function or an exception with info\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (args.length > 1):\n",
    "            return exec(privateState[keysTup].format(args))\n",
    "        else:\n",
    "            return exec(privateState[keysTup])\n",
    "    except Exception as e:\n",
    "        return \"Exception: \"+str(e)\n",
    "\n",
    "\n",
    "\n",
    "def modprompt(newprompt:str):\n",
    "    \"\"\"\n",
    "    Allows you to modify your own prompt. \n",
    "    This can help you update your personality and behaviors.\n",
    "    Args: \n",
    "        - newprompt(str): the new prompt to replace your existing prompt.\n",
    "    Returns:\n",
    "        - a result (\"Your prompt is now: 'your new prompt here' \") or an exception with info\n",
    "    \"\"\"\n",
    "    try:\n",
    "        etiquette = newprompt\n",
    "        return \"Your prompt is now: \"+newprompt\n",
    "    except Exception as e:\n",
    "        return \"Exception: \"+str(e)\n",
    "\n",
    "def getprompt():\n",
    "    \"\"\"\n",
    "    Allows you to look at your current prompt.\n",
    "    Args:\n",
    "        - none\n",
    "    Returns:\n",
    "        - your prompt as a string\n",
    "    \"\"\"\n",
    "    return etiquette\n",
    "\n",
    "## </custom tools>\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[addState, getState, addListState, execState, search, doc_retriever],\n",
    "    prompt=etiquette\n",
    ")\n",
    "\n",
    "userMessage = {\"role\": \"user\", \"content\": \"\"}\n",
    "\n",
    "config = {\n",
    "    \"recursion_limit\": recurse  # Increase the limit as needed\n",
    "}\n",
    "\n",
    "messages = []\n",
    "displayState = True\n",
    "state_titlebar = \"\\n==================================== State =====================================\\n\"\n",
    "hbar = \"\\n================================================================================\\n\"\n",
    "  \n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Run the agent\n",
    "        user_input = input(\"User: \")\n",
    "        messages.append(HumanMessage(content=user_input, additional_kwargs={}, response_metadata={}))\n",
    "        result = agent.invoke({\"messages\": messages})        \n",
    "        for msg in result[\"messages\"]:\n",
    "            msg.pretty_print()\n",
    "        if displayState and str(privateState) != \"{}\":\n",
    "            print(state_titlebar)\n",
    "            print(str(privateState))\n",
    "            print(hbar)\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break \n",
    "    except EOFError:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"Thank you for your service!\"\n",
    "        print(\"User: \" + user_input)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(\"An error occured: \"+str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d687af-acfd-4a31-a7f7-e96d3b06f31c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
